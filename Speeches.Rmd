Install the necessary packages
```{r}
install.packages("dplyr") # pipe operator
install.packages("tidytext") # unnest_tokens
install.packages("stopwords") # to remove french and english stop words
install.packages("SnowballC") # for stemming
```

Load the necessary packages
```{r}
library(dplyr)
library(tidytext)
library(stopwords)
library(SnowballC)
```

Load the dataset
```{r}
speeches_data <- read.csv('Speeches.csv', sep=';') 
speeches_data
```

Compare speeches' length
```{r}
# Add a column containing for each speech, its length
speeches_length <- speeches_data %>%
  mutate(Length = nchar(Speech))
speeches_data

# Historical order
speeches_length$President <- factor(speeches_length$President,
                          levels = c("Valéry Giscard d'Estaing (1974)", "François Mitterrand (1981)",	"François Mitterrand (1988)", "Jacques Chirac (1995)", "Jacques Chirac (2002)", "Nicolas Sarkozy (2007)", "François Hollande (2012)", "Emmanuel Macron (2017)", "Emmanuel Macron (2022)"))

# Create a speech length bar graph to compare them
ggplot(speeches_length, aes(x = President, y = Length)) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(x = "President", y = "Speech Length") +
  ggtitle("Inauguration Speech Length Comparison") +
  theme(plot.title = element_text(face = "bold", hjust = 0.5), # Bold title, centered
        panel.grid.major.x = element_blank(), # Remove x-axis grid lines
        axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels for better readability
```

Tokenize the text into words, remove stop words (french and english) and stem the surviving ones
```{r}
english_stopwords <- stopwords("en")
french_stopwords <- stopwords("fr")

speeches_tidy <- speeches_data %>%
  # Group by President
  group_by(President) %>%
  # Tokenize
  unnest_tokens(output = word, input = Speech) %>%
  # Added line number for future analysis (one line contains 10 words)
  mutate(line_number = ceiling(row_number() / 10)) %>%
  # Remove stop words
  anti_join(data.frame(word = english_stopwords), by = "word") %>%
  anti_join(data.frame(word = french_stopwords), by = "word") # Uncoment if you want stemming %>%
  # Apply stemming
  # Uncoment if you want stemming mutate(word = wordStem(word, language = "en"))
speeches_tidy
```

Analysis - TF (Term Frequency)
```{r}
# Extract the top 10 words in terms of frequency from each president's speeches
top10tf <- speeches_tidy %>%
  count(President, word) %>%
  group_by(President) %>%
  slice_max(n, n = 10, with_ties = F) # False to avoid multiple elements with the same value
top10tf

# Historical order
top10tf$President <- factor(top10tf$President,
                          levels = c("Valéry Giscard d'Estaing (1974)", "François Mitterrand (1981)",	"François Mitterrand (1988)", "Jacques Chirac (1995)", "Jacques Chirac (2002)", "Nicolas Sarkozy (2007)", "François Hollande (2012)", "Emmanuel Macron (2017)", "Emmanuel Macron (2022)"))

# Define my color palette
my_colors <- c("blue", "red", "red", "orange", "orange", "green", "magenta", "brown", "brown")

# Create the top 10 tf bar graph
ggplot(top10tf, aes(x = reorder_within(word, n, President), # To order by word frequency
                  y = n,
                  fill = President)) +
  geom_col(show.legend = F) + # To remove President legend
  coord_flip() + # To flip axis
  facet_wrap(~President, scales = "free", ncol = 2) + # To remove unused top10 words + space on x axis
  scale_x_reordered() + # To remove x axis legends
  scale_fill_manual(values = my_colors) + # To use my defined colors
  labs(x = NULL) + # To remove reorder labels
  ggtitle("Top 10 words by Term Frequency") +
  theme(plot.title = element_text(face = "bold", hjust = 0.5), # Bold title, centered
        panel.grid.major.y = element_blank()) # Remove y-axis grid lines
```

Analysis - TF-IDF (Term Frequency - Inverse Document Frequency)
```{r}
# - An indicator of the degree to which a word is uncommon but frequently used in a specific text
# - Used to find key words that reveal the personality of a text

# Extract the top 10 words in terms of tf-idf from each president's speeches
top10tfidf <- speeches_tidy %>%
  count(President, word) %>%
  # Combine the term frequency (TF) and inverse document frequency (IDF) calculations into a single step
  bind_tf_idf(term = word,           # Word
              document = President,  # Text delimiter
              n = n) %>%             # Word frequency
  group_by(President) %>%
  slice_max(tf_idf, n = 10, with_ties = F) # False to avoid multiple elements with the same value

# Historical order
top10tfidf$President <- factor(top10tfidf$President,
                          levels = c("Valéry Giscard d'Estaing (1974)", "François Mitterrand (1981)",	"François Mitterrand (1988)", "Jacques Chirac (1995)", "Jacques Chirac (2002)", "Nicolas Sarkozy (2007)", "François Hollande (2012)", "Emmanuel Macron (2017)", "Emmanuel Macron (2022)"))

# Create the top 10 tf-idf bar graph
ggplot(top10tfidf, aes(x = reorder_within(word, tf_idf, President), # To order by tf-idf
                  y = tf_idf,
                  fill = President)) +
  geom_col(show.legend = F) + # To remove President legend
  coord_flip() + # To flip axis
  facet_wrap(~President, scales = "free", ncol = 2) + # To remove unused top10 words + space on x axis
  scale_x_reordered() + # To remove x axis legends
  scale_fill_manual(values = my_colors) + # To use my previous defined colors
  labs(x = NULL) + # To remove reorder labels
  ggtitle("Top 10 words by Term Frequency - Inverse Document Frequency") +
  theme(plot.title = element_text(face = "bold", hjust = 0.5), # Bold title, centered
        panel.grid.major.y = element_blank()) # Remove y-axis grid lines
```

Sentimental Analysis using 'nrc' lexicon
Most of the time, we use 'nrc' lexicon only for pure sentiment analysis (positive or negative).
Nonetheless, this lexicon contains also 8 emotions.
Let's use them to implement a more exhaustive analysis.
```{r}
# Define a chunk (group of lines)
chunk_size <- 20 # lines

# Get sentiment dataframe
speeches_sentiment <- speeches_tidy %>%
  inner_join(get_sentiments("nrc")) %>% # Use 'nrc' lexicon
  count(President, index = line_number %/% chunk_size, sentiment) %>% # Create chunk
  group_by(President, index) %>%
  mutate(total_words = sum(n)) %>%
  ungroup() %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% # Reshape table
  mutate_at(vars(anger, anticipation, disgust, fear, joy, sadness, surprise, trust), ~ . / total_words * 100) # Calculate a percentage for each sentiment
speeches_sentiment

# Historical order
speeches_sentiment$President <- factor(speeches_sentiment$President,
                          levels = c("Valéry Giscard d'Estaing (1974)", "François Mitterrand (1981)",	"François Mitterrand (1988)", "Jacques Chirac (1995)", "Jacques Chirac (2002)", "Nicolas Sarkozy (2007)", "François Hollande (2012)", "Emmanuel Macron (2017)", "Emmanuel Macron (2022)"))

# Define a custom color palette for each sentiment
sentiment_palette <- c("anger" = "red", "anticipation" = "lightgreen", "disgust" = "pink",
                       "fear" = "darkgray", "joy" = "yellow", "negative" = "darkred",
                       "positive" = "darkgreen", "sadness" = "purple", "surprise" = "orange",
                       "trust" = "blue")

# Reshape the data into long format
speeches_sentiment <- speeches_sentiment %>%
  tidyr::pivot_longer(cols = c(anger, anticipation, disgust, fear, joy, negative, positive, sadness, surprise, trust),
                      names_to = "Sentiment",
                      values_to = "Percentage")

# Create the stacked bar graph
ggplot(speeches_sentiment, aes(x = factor(index), y = Percentage, fill = Sentiment)) +
  geom_bar(stat = "identity", position = "stack") +
  facet_wrap(~President, ncol = 2, scales = "free_x") +
  labs(x = paste0("Chunk (", chunck_size, " lines)"), y = "Percentage") + # Dynamic legend
  ggtitle("Sentiment Analysis by Chunk and President") +
  theme(plot.title = element_text(face = "bold", hjust = 0.5), # Bold title, centered
        panel.grid.major.y = element_blank()) + # Remove y-axis grid lines
  scale_fill_manual(values = sentiment_palette) # Use our custom color palette
```

Log Odds Ratio Analysis for Macron's speeches
As you know, President Macron is the actual French President but was already President before.
Let's compare his two investiture speeches to find some differences.
For this purpose, what's better than using log odds ration method.
$${\large\text{log odds ratio} = \log{\left(\frac{\left(\frac{n+1}{\text{total}+1}\right)_\text{Text A}}
                              {\left(\frac{n+1}{\text{total}+1}\right)_\text{Text B}}\right)}}$$
```{r}
# Extract the top 10 words in terms of log odds ratio from Macron's speeches (2017 and 2022)
top10lor <- speeches_tidy %>%
  filter(President %in% c("Emmanuel Macron (2017)", "Emmanuel Macron (2022)")) %>%
  count(President, word) %>%
  pivot_wider(names_from = President,
              values_from = n,
              values_fill = list(n = 0)) %>%
  rename(EM2017 = `Emmanuel Macron (2017)`,
         EM2022 = `Emmanuel Macron (2022)`) %>%
  # Add `+1` to all values so that the frequency is greater than zero
  mutate(ratio_EM2017 = ((EM2017 + 1) / (sum(EM2017 + 1))), # Weight of words in EM2017 speech
         ratio_EM2022 = ((EM2022 + 1) / (sum(EM2022 + 1))), # Weight of words in EM2022 speech
         odds_ratio = ratio_EM2017 / ratio_EM2022,
         log_odds_ratio = log(odds_ratio)) %>%
  group_by(President = ifelse(log_odds_ratio > 0, "EM2017", "EM2022")) %>%
  slice_max(abs(log_odds_ratio), n = 10, with_ties = F) %>%
  select(word, log_odds_ratio, President)

# Refill president column with President's full name
top10lor$President[top10lor$President == "EM2017"] <- "Emmanuel Macron (2017)"
top10lor$President[top10lor$President == "EM2022"] <- "Emmanuel Macron (2022)"

# Historical order
top10lor$President <- factor(top10lor$President,
                             levels = c("Emmanuel Macron (2017)", "Emmanuel Macron (2022)"))

# Create the top 10 log odds ratio bar graph
ggplot(top10lor, aes(x = reorder_within(word, log_odds_ratio, President), # To order by log odds ratio
                  y = log_odds_ratio,
                  fill = President)) +
  geom_col(show.legend = F) + # To remove President legend
  coord_flip() + # To flip axis
  facet_wrap(~President, scales = "free", ncol = 2) + # To remove unused top10 words + space on x axis
  scale_x_reordered() + # To remove x axis legends
  labs(x = NULL) + # To remove reorder labels
  ggtitle("Top 10 words by Log Odds Ration for Macron's speeches") +
  theme(plot.title = element_text(face = "bold", hjust = 0.5), # Bold title, centered
        panel.grid.major.y = element_blank()) # Remove y-axis grid lines
```
- The *sign** and **magnitude** tell us which words are more important in the speech
- A positive number greater than 0 indicates greater importance in EM2017's speech
- Negative numbers less than 0 have more weight in EM2022's speech
- If it is close to 0, it has similar weight in both speeches

Sentimental Analysis using 'bing' lexicon
Goal: Compare for each speech the distribution of positive and negative words.
Then, to compare only the positive and negative aspects, let's use "bing", which is the most inclusive lexicon for this.
```{r}
speeches_posneg <- speeches_tidy %>%
  inner_join(get_sentiments("bing")) %>% # Use 'bing' lexicon
  count(President, sentiment) %>%
  group_by(President) %>%
  mutate(percentage = n / sum(n) * 100) %>% # Compute distribution in %
  rename(Sentiment = sentiment) # Rename sentiment column for aesthetics reason (legend displaying)
speeches_posneg

# Historical order
speeches_posneg$President <- factor(speeches_posneg$President,
                          levels = c("Valéry Giscard d'Estaing (1974)", "François Mitterrand (1981)",	"François Mitterrand (1988)", "Jacques Chirac (1995)", "Jacques Chirac (2002)", "Nicolas Sarkozy (2007)", "François Hollande (2012)", "Emmanuel Macron (2017)", "Emmanuel Macron (2022)"))

# Create the circular graphs
ggplot(speeches_posneg, aes(x = "", y = percentage, fill = Sentiment)) +
  geom_bar(stat = "identity", width = 1, color = "white") +
  geom_text(aes(
    label = paste0(round(percentage), "%")), # Display percentage values on each graph
    position = position_stack(vjust = 0.5),
    color = "white",
    size = 3) +
  coord_polar("y", start = 0) +
  facet_wrap(~President, strip.position = "bottom", ncol = 3, labeller = label_wrap_gen(width = 20)) +
  scale_fill_manual(values = c("negative" = "red", "positive" = "darkgreen")) +
  theme_void() + # Hide ugly graph details
  ggtitle("Speeches positive/negative words distribution") +
  theme(
    legend.position = "right",
    plot.title = element_text(face = "bold", hjust = 0.5),
    strip.text = element_text(size = 8, face = "bold"),
    legend.margin = margin(t = 10, r = 10, b = 10, l = 50)
  )
```