Load the necessary packages
```{r}
library(dplyr) # pipe operator
library(tidytext) # unnest_tokens
library(stopwords) # to remove french and english stopwords
library(SnowballC) # for stemming
```

Load the dataset
```{r}
speeches_data <- read.csv('Speeches.csv', sep=';') 
speeches_data
```

Tokenize the text into words, remove stop words (french and english) and stem the surviving ones
```{r}
english_stopwords <- stopwords("en")
french_stopwords <- stopwords("fr")

speeches_tidy <- speeches_data %>% 
  # Tokenize
  unnest_tokens(output = word, input = Speech) %>%
  # Remove stop words
  anti_join(data.frame(word = english_stopwords), by = "word") %>%
  anti_join(data.frame(word = french_stopwords), by = "word") %>%
  # Apply stemming
  mutate(word = wordStem(word, language = "en"))
speeches_tidy
```

Count the frequency of words in all the speeches
```{r}
speeches_frequency <- speeches_tidy %>% 
  count(word, sort=T)
speeches_frequency
```